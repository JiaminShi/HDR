{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# title of the project \n",
    "## a list of author(s) names,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "a few short sentences highlighting the main points of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "(3-4 paragraphs) reviewing your topic, related technical ideas/algorithms, your selected methodology/approach, its motivation, and outlining the overall structure/organization of the report. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "from skimage import color\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "import matplotlib.image as image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "# source: https://www.easyhdr.com/examples/mountains\n",
    "im_auto_expose = image.imread(\"images/laurenziana_0.jpg\")\n",
    "im_under_expose = image.imread(\"images/laurenziana_-2.jpg\")\n",
    "im_over_expose = image.imread(\"images/laurenziana_+2.jpg\")\n",
    "\n",
    "imagebracket = np.array([im_under_expose,im_auto_expose,im_over_expose])\n",
    "\n",
    "log_t = [-2,0,2]\n",
    "\n",
    "# plot \n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.subplot(221)\n",
    "plt.imshow(im_auto_expose)\n",
    "plt.title(\"auto setting exposure image(0)\")\n",
    "plt.subplot(222)\n",
    "plt.imshow(im_under_expose)\n",
    "plt.title(\"under-exposure image(-2)\")\n",
    "plt.subplot(223)\n",
    "plt.imshow(im_over_expose)\n",
    "plt.title(\"over-exposure image(+2)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### 1. Estimate the radiometric response function from the aligned images\n",
    "\n",
    "Estimate irradiance values $E_i$ and the radiometric response function $f$ at the same time. \n",
    "\n",
    "$$z_{ij} = f(E_i,t_j)$$ where $t_j$ is the exposure time for the $j$th image. \n",
    "\n",
    "The inverse response curve $f^{−1}$ is given by\n",
    "$$f^{−1}(z_{ij}) = E_i t_j$$\n",
    "\n",
    "Taking logarithms of both sides \n",
    "$$g(z_{ij})=\\log f^{-1}(z_{ij})=\\log E_i +\\log t_j$$\n",
    " ($g$ maps pixel values $z_{ij}$ into log irradiance)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we need make the reponse curve smooth by adding a second-order smoothness constraint\n",
    "$$\\lambda\\sum_k g''(k)^2 = \\lambda\\sum[g(k-1) - 2g(k)+ g(k+1)]^2$$\n",
    "\n",
    "Since pixel values are more reliable in the middile of their range, they also add a weight function\n",
    "$$ w(z)=\\left\\{\n",
    "\\begin{aligned}\n",
    "z-z_{min} & &  z \\le (z_{min}+z_{max})/2 \\\\\n",
    "z_{max}-z & & z \\gt (z_{min}+z_{max})/2 \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all together we get a least squares problem to estimate the radiometric response function $g$ and irradiance values $E_i$\n",
    "\n",
    "$$E = \\sum_i\\sum_jw(z_{i,j})[g(z_{i,j}) - \\log E_i - \\log t_j]^2 + \\lambda\\sum_k g''(k)^2$$\n",
    "\n",
    "In other word, we are solve the two equations \n",
    "$$ w(z_{i,j}) g(z_{i,j}) - w(z_{i,j}) \\log E_i  = w(z_{i,j}) \\log t_j $$ \n",
    "$$\\lambda[g(z_{i,j}-1) - 2g(z_{i,j})+ g(z_{i,j}+1)] = 0$$\n",
    "together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assume that $t_j$ is known\n",
    "\n",
    "The response value $g_k = g(k)$, where g can be discretized according to the 256 pixel values commonly observed in eight-bit images. (The response curves are calibrated separately for each color channel.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modified from gsolve.m\n",
    "\n",
    "Solve for imaging system response function\n",
    "\n",
    "Given a set of pixel values observed for several pixels in several\n",
    "images with different exposure times, this function returns the\n",
    "imaging system’s response function\n",
    "\n",
    "\n",
    "Z(i,j): the pixel values of pixel location number i in image j\n",
    "\n",
    "B(j): the log delta t, or log shutter speed, for image j\n",
    "\n",
    "l: lamdba, the constant that determines the amount of smoothness\n",
    "\n",
    "w(z): the weighting function value for pixel value z\n",
    "\n",
    "'''\n",
    "zmin = 0.\n",
    "zmax = 255.\n",
    "\n",
    "def weight_hat(z):\n",
    "    return min(z-zmin, zmax-z)\n",
    "\n",
    "def gsolve(Z, B, lmd, w=weight_hat):\n",
    "\n",
    "    locations = Z.shape[0]\n",
    "    sequences = Z.shape[1]\n",
    "    n = 256  # [0, 255]\n",
    "    A = np.zeros((locations * sequences + n - 1, locations + n), dtype=float)\n",
    "    b = np.zeros(A.shape[0], dtype=float)\n",
    "\n",
    "    #  Include the data−fitting equations\n",
    "    k = 0\n",
    "    for i in range(locations):\n",
    "        for j in range(sequences): \n",
    "            wij = w(Z[i, j])\n",
    "            A[k, int(Z[i, j])] = wij\n",
    "            A[k, n + i] = -wij\n",
    "            b[k] = wij * B[j]\n",
    "            k += 1\n",
    "\n",
    "    # Fix the curve by setting its middle value to 0, i.e. g(128) = 0    \n",
    "    A[k, 128] = 1   \n",
    "    k += 1\n",
    "\n",
    "    # Include the smoothness equations\n",
    "    for i in range(n-2): #(0, 253) 254 equations\n",
    "        wi = w(i + 1)\n",
    "        A[k, i] = lmd * wi\n",
    "        A[k, i+1] = -2 * lmd * wi\n",
    "        A[k, i+2] = lmd * wi\n",
    "        k += 1\n",
    "\n",
    "    # Solve the system\n",
    "    x = np.linalg.lstsq(A, b)[0]\n",
    "    g = x[:n]\n",
    "    lnE = x[n:]\n",
    "\n",
    "    return (g, lnE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepack is to flat each input RGB image into a vector for each channle and pack them into three 2d array\n",
    "# input: np-array\n",
    "# return three Z(i,j)(see above) for each channel \n",
    "def imagepack(imagearray):\n",
    "    num_image = imagearray.shape[0]\n",
    "    # imagesize refer to 1-d image size\n",
    "    imagesize = imagearray[0].shape[0]*imagearray[0].shape[1]\n",
    "    imagepack = np.zeros((3, imagesize,num_image))\n",
    "    # naive loop ; can be optimized later\n",
    "    for i in range(num_image):\n",
    "        for j in range(3):\n",
    "            imagepack[j,:,i] = np.ndarray.flatten(imagearray[i][:,:,j])\n",
    "    return imagepack\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP,GP,BP = imagepack(imagebracket) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample\n",
    "\n",
    "Question: how do we sample the pixel value $z_{ij}$? What is the sample ratio?\n",
    "\n",
    "The linear system should be overdetermined. For $N$ sample pixels in each image and $P$ images, we need $N \\times P > (Z_{max} -Z_{min}) + N$ (i.e. number of given parameters is greater than number of unknowns)\n",
    "\n",
    "Suppose we have 3 images, $2N > 255$, $N > 128 $ should be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Technical Discuss: Weakness/Strength Of Difference Sample Methods}$\n",
    "\n",
    "\n",
    "For randomSample method - pick pixel randomly\n",
    "\n",
    "- Weakness: not stable - some random result will lead to very bad estimate, for example, only sampling pixels with intensity 10\n",
    "\n",
    "- Strength: very quick and if our sample size is big enough, the result will be representative\n",
    "\n",
    "\n",
    "For windowSample method - pick pixel randomly:\n",
    "\n",
    "- Weakness: not so stable and having no idea how intensity distributes among the whole images. In some extreme case, it may fail to sample some pixel with certain intensity. Also, as Debevec and Malik 1997 indicated we better avoid highly-variance areas, this schema may visit those bad areas\n",
    "\n",
    "- Strength: very quick and it also goes through the whole images and in some way, it will be representative. \n",
    "\n",
    "For pixelCoverSample method - random select k pixels for each pixel value ([0,255])\n",
    "\n",
    "- Weakness: slow and have to go through the whole image to know the capacity of the k. Also it require shuffle/couting schema to do randomly sample. Fataly sometimes this schema does not work if any intensity is missing\n",
    "\n",
    "- Strength: all different intensity pixels get reported. Much more representative\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample function\n",
    "# general template:\n",
    "# inputimg: np.array - like Z(i,j)(see above) ; parameters for different sampling schemas\n",
    "# output: sampled input\n",
    "\n",
    "\n",
    "# random chose \"outputsize\" pixels\n",
    "def randomSample(inputimg,outputsize):\n",
    "    outputsize = int(outputsize)\n",
    "    indexrange = inputimg.shape[0]\n",
    "    num_image = inputimg.shape[1]\n",
    "    output = np.zeros((outputsize,num_image))\n",
    "    sampleindex = np.random.choice(indexrange,size=outputsize,replace=False)\n",
    "    for i in range(num_image):\n",
    "        output[:,i] = inputimg[sampleindex,i]\n",
    "    return output\n",
    "\n",
    "\n",
    "# choose pixels per windowsize where windowsize = floor(num of pixel / outputsize)\n",
    "def windowSample(inputimg,outputsize):\n",
    "    outputsize = int(outputsize)\n",
    "    indexrange = inputimg.shape[0]\n",
    "    num_image = inputimg.shape[1]\n",
    "    windowsize = int(indexrange/outputsize)\n",
    "    output = np.zeros((outputsize,num_image))\n",
    "    sampleindex = np.arange(outputsize) * windowsize\n",
    "    for i in range(num_image):\n",
    "        output[:,i] = inputimg[sampleindex,i]\n",
    "    return output\n",
    "\n",
    "######## warning: \n",
    "######## pixelCoverSample is not so good since sometimes, some certain intensity value will be absent\n",
    "######## for exmaple, int the toy image, we don't have 0 \n",
    "######## might try some more tolerant sampling schema\n",
    "\n",
    "# random select k pixels for each pixel value ([0,255])\n",
    "# base: using which image as a standard to pick index\n",
    "# if k is too larger, the output will base on the maxmum possible k value\n",
    "def pixelCoverSample(inputimg,k,base = 1):\n",
    "    indexrange = inputimg.shape[0]\n",
    "    num_image = inputimg.shape[1]\n",
    "    baseimg = inputimg[:,base]\n",
    "    print(baseimg)\n",
    "    pixelrange = 256\n",
    "    # i copy the inputimg since i will call shuffle later, shuffle is a in-place function\n",
    "    imgcopy = np.copy(inputimg)\n",
    "    \n",
    "    # check whether input k is feasible\n",
    "    freqcount = np.zeros(pixelrange)\n",
    "    for i in range(indexrange):\n",
    "        freqcount[int(baseimg[i])] = freqcount[int(baseimg[i])] + 1\n",
    "    maxk = np.amin(freqcount)\n",
    "    kval = k if maxk >= k else maxk\n",
    "    if kval != k:\n",
    "        print(\"warning: the given k is more than the capacity!\")\n",
    "    if kval == 0:\n",
    "        print(\"warning: the capacity is zero\")\n",
    "        return\n",
    "    # sample part:\n",
    "    # i used an inelegant method ; can improve later\n",
    "    # better idea - store some info while check whther k is feasible\n",
    "    # Or we can use some buind-in liabary - I did not find yet\n",
    "\n",
    "    output = np.zeros((kval * pixelrange,num_image))\n",
    "    # shuffle the imgs so that we have a random behavior\n",
    "    np.apply_along_axis(np.random.shuffle,1,imgcopy)\n",
    "    coutmap = np.full((pixelrange*kval),kval)\n",
    "    # i is the index of imgcopy\n",
    "    # j is the number of elements we already have in output\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while True:\n",
    "        if j == pixelrange*kval:\n",
    "            break\n",
    "        else:\n",
    "            tempval = imgcopy[i]\n",
    "            if coutmap[int(tempval[base])] != 0:\n",
    "                output[j,:] = imgcopy[i,:]\n",
    "                coutmap[int(tempval[base])] = coutmap[int(tempval[base])] - 1\n",
    "                j = j + 1\n",
    "            i = i + 1\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Extension: variance-driven sampling}$\n",
    "\n",
    "$\\textbf{Idea:}$ \n",
    "\n",
    "Debevec and Malik 1997 indicated \"Furthermore, the pixels are best sampled from regions of the image with low intensity variance so that radiance can be assumed to be constant across the area of the pixel, and the effect of optical blur of the imaging system is minimized\"\n",
    "\n",
    "In this, we can introduce a biased sample schema that the probablity P of each point $X_{ij}$ get sampled is based on its local gradient\n",
    "\n",
    "\n",
    "$$W_{i,j} = 1 - sigmoid(||\\nabla X_{ij}||)$$\n",
    "\n",
    "$$p(X_{ij}) = \\frac{W_{ij}}{\\sum_{p,q}W_{p,q}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use sigmoid-like function to map our gradient into probality\n",
    "# subjective to change\n",
    "# maybe slow due to floating number\n",
    "def decreaseSigmoid(a):\n",
    "    return 1 - 1/(1 + np.exp(-1*a))\n",
    "\n",
    "vfunc = np.vectorize(decreaseSigmoid)\n",
    "\n",
    "x = np.matrix( [[1,2],[2,3]])\n",
    "y = vfunc(x)\n",
    "y = np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:\n",
    "# imgpack: data from imagePace\n",
    "# base: choose which image as basis to caculate local variance\n",
    "# shape: orignal shape\n",
    "# output:\n",
    "# 1-d array - the gradient of the image \n",
    "def GradientMap(imgpack,shape,base=1):\n",
    "    baseimg = imgpack[:,base]\n",
    "    baseimg = baseimg.reshape(shape)\n",
    "    yGadient = np.gradient(baseimg,axis =0)\n",
    "    xGadient = np.gradient(baseimg,axis =1)\n",
    "    result = np.sqrt(yGadient*yGadient + xGadient*xGadient)\n",
    "    return result\n",
    "\n",
    "# input: \n",
    "# Gradient:data from GradientMap\n",
    "# functionvector: function vector applying to each pixel in the image; see numpy.vectorize\n",
    "# output: \n",
    "# the weight map for each pixel\n",
    "def ProbMap(Gradient, functionvector):\n",
    "    result = functionvector(Gradient)\n",
    "    result = result / np.sum(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test block - visualize result \n",
    "GradientResult = GradientMap(RP,(im_auto_expose.shape[0],im_auto_expose.shape[1]))\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.title(\"gradient map of red channel of auto setting exposure image\")\n",
    "plt.imshow(GradientResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize result \n",
    "promap = ProbMap(GradientResult,vfunc)\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.title(\"probabality map of red channel of auto setting exposure image - sigmoid transfered\")\n",
    "plt.imshow(promap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sampling block\n",
    "# input:\n",
    "# imgPack: data from imagePack\n",
    "# probmap: data from ProbMap\n",
    "# ouputsize: size of the sample \n",
    "# output:\n",
    "# sampled imagePack\n",
    "def gradientDrivenSample(imgPack,probmap,outputsize):\n",
    "    pvector = np.ndarray.flatten(probmap)\n",
    "    outputsize = int(outputsize)\n",
    "    indexrange = imgPack.shape[0]\n",
    "    num_image = imgPack.shape[1]\n",
    "    output = np.zeros((outputsize,num_image))\n",
    "    sampleindex = np.random.choice(indexrange,size=outputsize,replace=False,p=pvector)\n",
    "    for i in range(num_image):\n",
    "        output[:,i] = imgPack[sampleindex,i]\n",
    "    return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the log response function and result image\n",
    "\n",
    "Once we have the sample ($z$) and reponse function $g$, we could use it to print figure like 10.13\n",
    "\n",
    "If the images are noise free, we can use any non-saturated pixel value to estimate the corresponding radiance by mapping it through the inverse response curve $E = g(z)$.\n",
    "\n",
    "Debevec and Malik (1997) use a hat function (10.7) which accentuates mid-tone pixels while avoiding saturated values.\n",
    "\n",
    "# Question: How do we choose $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "\n",
    "lmd = 100\n",
    "#### we use window sample here\n",
    "targetsize = 1000 #(im_auto_expose.shape[1] * im_auto_expose.shape[0]) / 100\n",
    "sampledRP = windowSample(RP,targetsize)\n",
    "sampledGP = windowSample(GP,targetsize)\n",
    "sampledBP = windowSample(BP,targetsize)\n",
    "Rg, RinE = gsolve(sampledRP, log_t, lmd)\n",
    "Gg, GinE = gsolve(sampledGP, log_t, lmd)\n",
    "Bg, BinE = gsolve(sampledBP, log_t, lmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "#### use gradient drive sample schema here\n",
    "\n",
    "RPpromap = ProbMap(GradientMap(RP,(im_auto_expose.shape[0],im_auto_expose.shape[1])),vfunc)\n",
    "GPpromap = ProbMap(GradientMap(GP,(im_auto_expose.shape[0],im_auto_expose.shape[1])),vfunc)\n",
    "BPpromap = ProbMap(GradientMap(BP,(im_auto_expose.shape[0],im_auto_expose.shape[1])),vfunc)\n",
    "\n",
    "\n",
    "vDsampledRP = gradientDrivenSample(RP,RPpromap,targetsize)\n",
    "vDsampledGP = gradientDrivenSample(GP,GPpromap,targetsize)\n",
    "vDsampledBP = gradientDrivenSample(BP,BPpromap,targetsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "#### we use radient drive sample here\n",
    "#### notice this can be very slow\n",
    "vDRg, vDRinE = gsolve(vDsampledRP,[-2,0,2], lmd)\n",
    "vDGg, vDGinE = gsolve(vDsampledGP,[-2,0,2], lmd)\n",
    "vDBg, vDBinE = gsolve(vDsampledBP,[-2,0,2], lmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelrange = np.arange(256)\n",
    "\n",
    "fig = plt.figure(figsize=(6,12))\n",
    "plt.subplot(311)\n",
    "plt.plot(RinE, sampledRP[:,0], 'x', color = 'khaki', label='image1')\n",
    "plt.plot(RinE, sampledRP[:,1], 'x', color = 'palegreen', label='image2')\n",
    "plt.plot(RinE, sampledRP[:,2], 'x', color = 'skyblue', label='image3')\n",
    "plt.plot(Rg, pixelrange, color='red')\n",
    "plt.legend()\n",
    "plt.title(\"Pixel value over log exposure (Red) - window sample schema\")\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(GinE, sampledGP[:,0], 'x', color = 'khaki', label='image1')\n",
    "plt.plot(GinE, sampledGP[:,1], 'x', color = 'palegreen', label='image2')\n",
    "plt.plot(GinE, sampledGP[:,2], 'x', color = 'skyblue', label='image3')\n",
    "plt.plot(Gg, pixelrange, color='green')\n",
    "plt.legend()\n",
    "plt.title(\"Pixel value over log exposure (Green) - window sample schema\")\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(BinE, sampledBP[:,0], 'x', color = 'khaki', label='image1')\n",
    "plt.plot(BinE, sampledBP[:,1], 'x', color = 'palegreen', label='image2')\n",
    "plt.plot(BinE, sampledBP[:,2], 'x', color = 'skyblue', label='image3')\n",
    "plt.plot(Bg, pixelrange, color='blue')\n",
    "plt.legend()\n",
    "plt.title(\"Pixel value over log exposure (Blue) - window sample schema\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,12))\n",
    "plt.subplot(311)\n",
    "plt.plot(vDRinE, vDsampledRP[:,0], 'x', color = 'khaki', label='image1')\n",
    "plt.plot(vDRinE, vDsampledRP[:,1], 'x', color = 'palegreen', label='image2')\n",
    "plt.plot(vDRinE, vDsampledRP[:,2], 'x', color = 'skyblue', label='image3')\n",
    "plt.legend()\n",
    "plt.title(\"Pixel value over log exposure (Red) - gradient-drive sample schema\")\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(vDGinE, vDsampledGP[:,0], 'x', color = 'khaki', label='image1')\n",
    "plt.plot(vDGinE, vDsampledGP[:,1], 'x', color = 'palegreen', label='image2')\n",
    "plt.plot(vDGinE, vDsampledGP[:,2], 'x', color = 'skyblue', label='image3')\n",
    "plt.legend()\n",
    "plt.title(\"Pixel value over log exposure (Green) - gradient-drive sample schema\")\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(vDBinE, vDsampledBP[:,0], 'x', color = 'khaki', label='image1')\n",
    "plt.plot(vDBinE, vDsampledBP[:,1], 'x', color = 'palegreen', label='image2')\n",
    "plt.plot(vDBinE, vDsampledBP[:,2], 'x', color = 'skyblue', label='image3')\n",
    "plt.legend()\n",
    "plt.title(\"Pixel value over log exposure (Blue) - gradient-drive sample schema\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot block \n",
    "\n",
    "#'''\n",
    "\n",
    "plt.figure(4,figsize = (10, 6))\n",
    "plt.plot(Rg, pixelrange, 'o', color='red')\n",
    "plt.plot(Gg, pixelrange, 'o', color='green')\n",
    "plt.plot(Bg, pixelrange, 'o', color='blue')\n",
    "\n",
    "plt.title(\"estimated g over pixel - window sample schema\")\n",
    "#'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pixelrange = np.arange(256)\n",
    "plt.figure(5,figsize = (12, 8))\n",
    "plt.plot(vDRg, pixelrange, 'o', color='red')\n",
    "plt.plot(vDGg, pixelrange, 'o', color='green')\n",
    "plt.plot(vDBg, pixelrange, 'o', color='blue')\n",
    "plt.title(\"estimated g over pixel - gradient-drive sample schema\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estimate a radiance map by selecting of blending pixels from different exposures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Copy from the book directlt lol, need to be reformated later)\n",
    "\n",
    "The naive way to measure exposures is\n",
    "\n",
    "$$\\log E_i   = g(z_{ij}) - \\log t_j$$\n",
    "\n",
    "Unfortunately, pixels are noisy, especially under low-light conditions when fewer photons arrive at the sensor. \n",
    "\n",
    "Mitsunaga and Nayar (1999) show that in order to maximize the signal-to-noise ratio (SNR), the weighting function must emphasize both higher pixel values and larger gradients in the transfer function\n",
    "$$\n",
    "w(z)=f^{-1}(z)/f^{'-1}(z)\n",
    "$$\n",
    "\n",
    "(Note that there is a small error in the book, the measurement of weight function should based the inverse of reponse function **without logarithm**. Also, weight function should always be **positive**)\n",
    "\n",
    "\n",
    "the weights $w$ are used to form the final irradiance estimate\n",
    "\n",
    "$$\n",
    "\\log E_i = \\frac{\\sum_j w(z_{ij})[g(z_{ij})-\\log t_j]}{\\sum_j w(z_{ij})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:\n",
    "# g : the return data from g-solver \n",
    "# output:\n",
    "# result: the weight map\n",
    "def weightgenerate(g):\n",
    "    trans = np.exp(g)\n",
    "    gprime = np.gradient(trans)\n",
    "    result = np.array(trans/gprime)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:\n",
    "# g : the return data from g-solver \n",
    "# weight: the return data from weightgenerate correspond to g\n",
    "# t: log shutter speed, for image j\n",
    "# imgPack: the return data from imagepack\n",
    "# output:\n",
    "# logE_i for each pixel - np array\n",
    "def logEEstimate(g,weight,t,imgPack):\n",
    "    size = imgPack.shape[0]\n",
    "    num_img = imgPack.shape[1]\n",
    "    result = np.zeros(size)\n",
    "    for i in range(size):\n",
    "        temp = 0\n",
    "        weightsum = 0\n",
    "        for j in range(num_img):\n",
    "            temp = temp + weight[int(imgPack[i,j])] * (g[int(imgPack[i,j])] - t[j])\n",
    "            weightsum = weightsum + weight[int(imgPack[i,j])]\n",
    "        result[i] = temp/weightsum\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "## estimate g prime g' for each channel\n",
    "Rweight = weightgenerate(Rg)\n",
    "Gweight = weightgenerate(Gg)\n",
    "Bweight = weightgenerate(Bg)\n",
    "RglogE = logEEstimate(Rg,Rweight,[-2,0,2],RP)\n",
    "GglogE = logEEstimate(Gg,Gweight,[-2,0,2],GP)\n",
    "BglogE = logEEstimate(Bg,Bweight,[-2,0,2],BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tone map the resulting high dynamic range (HDR) image back into a displayable gamut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually necessary to display the HDR image on a lower gamut screen.\n",
    "\n",
    "1. Global Transfer Curve (i.e Gamma Curve) (Larson, Rushmeier, and Pattanaik 2005)\n",
    "    - If Gamma curve is applied seperate to each channel, then the color is less saturated \n",
    "    - If Gamma curve is applied to the luminance channel, then result is better. (the image is splited up into luminance and chrominance components $L^*a^*b^*$\n",
    "2. If the image has wide range of exposures, we can divide each pixel by the average brightness in a region around it, like dodging and burning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_img = np.zeros(im_auto_expose.shape)\n",
    "logEs = [RglogE, GglogE, BglogE]\n",
    "for i in range(3):\n",
    "    result_img[:,:,i] = (logEs[i].reshape(im_auto_expose.shape[0], im_auto_expose.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal2image(img, max_value = 255.):\n",
    "    ret = img.copy()\n",
    "    ret -= img.min()\n",
    "    ret *= max_value / ret.max()\n",
    "    return ret\n",
    "\n",
    "def image2normal(img):\n",
    "    min_value = img.min()\n",
    "    max_value = img.max()\n",
    "    normal = (img - img.min()) / (max_value - min_value)\n",
    "    return normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linearly maped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_linearMap = normal2image(result_img).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma correction is, in the simplest cases, defined by the following power-law expression:\n",
    "\n",
    "$ V_{\\text{out}}=A{V_{\\text{in}}^{\\gamma }}$\n",
    "\n",
    "where the non-negative real input value $V_{\\text{in}}$ is raised to the power $\\gamma$  and multiplied by the constant A, to get the output value$V_{\\text{out}}$. In the common case of A = 1, inputs and outputs are typically in the range 0–1.\n",
    "\n",
    "#### Gamma applied to each color channel independentlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_normal = image2normal(result_img)\n",
    "\n",
    "def gamma(Vin, gamma = 0.5):\n",
    "    return np.power(Vin, 1 / gamma)\n",
    "\n",
    "img_gamColor = gamma(img_normal)\n",
    "img_gamColor = normal2image(img_gamColor).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gamma applied to intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = color.rgb2lab(img_normal)\n",
    "l_channel = lab[:,:,0]\n",
    "l_max = l_channel.max()\n",
    "l_gamma = normal2image(gamma(image2normal(l_channel)), l_max)\n",
    "lab[:,:,0] = l_gamma\n",
    "img_gamIntensity = img_as_ubyte(color.lab2rgb(lab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dodging and burning (Linear Filters)\n",
    "lab2 = color.rgb2lab(img_normal)\n",
    "l_channel = lab2[:,:,0]\n",
    "hh = np.log(l_channel)\n",
    "h_low = skimage.filters.gaussian(hh,  sigma=100 , truncate=2.0)\n",
    "h_high = hh - h_low\n",
    "h = h_low + h_high * 0.1\n",
    "l = np.exp(hh)\n",
    "lab2[:,:,0] = l\n",
    "img_DaB = img_as_ubyte(color.lab2rgb(lab2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSaturation(img):\n",
    "    return color.rgb2hsv(img)[:,:,1].mean()\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img_linearMap)\n",
    "plt.title('linear map, S = {:.4f}'.format(computeSaturation(img_linearMap)))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(img_gamColor)\n",
    "plt.title('Gamma applied to each color channel, S = {:.4f}'.format(computeSaturation(img_gamColor)))\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(img_gamIntensity)\n",
    "plt.title('Gamma applied to intensity, S = {:.4f}'.format(computeSaturation(img_gamIntensity)))\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(img_DaB)\n",
    "plt.title('original image, S = {:.4f}'.format(computeSaturation(img_DaB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance-Driven Sample (haven't finished yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiances = [vDRg, vDGg, vDBg]\n",
    "samples = [RP, GP, BP]\n",
    "result_img2 = np.zeros(im_auto_expose.shape)\n",
    "\n",
    "for i in range(len(radiances)):\n",
    "    weight = weightgenerate(radiances[i])\n",
    "    result_img2[:,:,i] = (logEEstimate(radiances[i],weight,[-2,0,2],samples[i]).reshape(im_auto_expose.shape[0], im_auto_expose.shape[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_linearMap = normal2image(result_img2).astype(np.uint8)\n",
    "\n",
    "img_normal = image2normal(result_img2)\n",
    "\n",
    "img_gamColor = gamma(img_normal)\n",
    "img_gamColor = normal2image(img_gamColor).astype(np.uint8)\n",
    "\n",
    "## lab\n",
    "\n",
    "lab = color.rgb2lab(img_normal)\n",
    "l_channel = lab[:,:,0]\n",
    "l_max = l_channel.max()\n",
    "l_gamma = normal2image(gamma(image2normal(l_channel)), l_max)\n",
    "lab[:,:,0] = l_gamma\n",
    "img_gamIntensity = img_as_ubyte(color.lab2rgb(lab))\n",
    "\n",
    "\n",
    "## \n",
    "lab2 = color.rgb2lab(img_normal)\n",
    "l_channel = lab2[:,:,0]\n",
    "hh = np.log(l_channel)\n",
    "h_low = skimage.filters.gaussian(hh,  sigma=100 , truncate=2.0)\n",
    "h_high = hh - h_low\n",
    "h = h_low + h_high * 0.1\n",
    "l = np.exp(hh)\n",
    "lab2[:,:,0] = l\n",
    "img_DaB = img_as_ubyte(color.lab2rgb(lab2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,16))\n",
    "'''\n",
    "plt.subplot(222)\n",
    "plt.imshow(img_linearMap)\n",
    "plt.title('linear map, S = {:.4f}'.format(computeSaturation(img_linearMap)))\n",
    "'''\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(img_DaB)\n",
    "plt.title('linear map, S = {:.4f}'.format(computeSaturation(img_DaB)))\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(img_gamColor)\n",
    "plt.title('Gamma applied to each color channel, S = {:.4f}'.format(computeSaturation(img_gamColor)))\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(img_gamIntensity)\n",
    "plt.title('Gamma applied to intensity, S = {:.4f}'.format(computeSaturation(img_gamIntensity)))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(im_auto_expose)\n",
    "plt.title('original image, S = {:.4f}'.format(computeSaturation(im_auto_expose)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extentions\n",
    "-  multi-exposure images taken without a tripod using homography-based registration of the sequence\n",
    "- drop the assumption that exposure is known\n",
    "\n",
    "(both are metioned in the book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the assumption that exposure is known\n",
    "\n",
    "Suppose $\\log t_j$ are unknowns in our least squares problem.\n",
    "\n",
    "$$E = \\sum_i\\sum_jw(z_{i,j})[g(z_{i,j}) - \\log E_i - \\log t_j]^2 + \\lambda\\sum_k g''(k)^2 + \\eta \\sum_j(t_j - \\hat{t}_j)^2$$\n",
    "\n",
    "In other word, we are solve the three equations together to estimate the radiometric response function $g$, irradiance values $E_i$ and $t_j$\n",
    "$$ w(z_{i,j}) g(z_{i,j}) - w(z_{i,j}) \\log E_i  - w(z_{i,j}) \\log t_j= 0 $$ \n",
    "$$\\lambda[g(z_{i,j}-1) - 2g(z_{i,j})+ g(z_{i,j}+1)] = 0$$\n",
    "$$ \\eta (t_j - \\hat{t}_j) = 0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modified from gsolve.m\n",
    "\n",
    "Solve for imaging system response function\n",
    "\n",
    "Given a set of pixel values observed for several pixels in several\n",
    "images with different exposure times, this function returns the\n",
    "imaging system’s response function\n",
    "\n",
    "\n",
    "Z(i,j): the pixel values of pixel location number i in image j\n",
    "\n",
    "l: lamdba, the constant that determines the amount of smoothness\n",
    "\n",
    "w(z): the weighting function value for pixel value z\n",
    "\n",
    "eta: the constraint for exposure time, should be positive for ascending exposure time sequence\n",
    "\n",
    "t_hat: the nominal value of default image (middle image in image sequence)\n",
    "'''\n",
    "\n",
    "def gsolve2(Z, lmd, eta = 10, t_hat = 0, w=weight_hat):\n",
    "\n",
    "    locations = Z.shape[0]\n",
    "    sequences = Z.shape[1]\n",
    "    n = 256  # [0, 255]\n",
    "    A = np.zeros((locations * sequences + n + sequences - 1, n + locations + sequences), dtype=float)\n",
    "    b = np.zeros(A.shape[0], dtype=float)\n",
    "\n",
    "    #  Include the data−fitting equations\n",
    "    k = 0\n",
    "    for i in range(locations):\n",
    "        for j in range(sequences): \n",
    "            wij = w(Z[i, j])\n",
    "            A[k, int(Z[i, j])] = wij\n",
    "            A[k, n + i] = -wij\n",
    "            A[k, n + locations + j] = -wij #b[k] = wij * B[j]\n",
    "            k += 1\n",
    "\n",
    "    # Fix the curve by setting its middle value to 0, i.e. g(128) = 0    \n",
    "    A[k, 128] = 1   \n",
    "    k += 1\n",
    "    \n",
    "    # Include the smoothness equations\n",
    "    for i in range(n-2): \n",
    "        wi = w(i + 1)\n",
    "        A[k, i] = lmd * wi\n",
    "        A[k, i+1] = -2 * lmd * wi\n",
    "        A[k, i+2] = lmd * wi\n",
    "        k += 1    \n",
    "    \n",
    "    # exposure time constraints\n",
    "    for i in range(sequences):\n",
    "        A[k, n + locations + i] = eta \n",
    "        b[locations * sequences + n + i - 1] =  eta * (i - sequences//2 + t_hat)\n",
    "        k += 1\n",
    " \n",
    "    # Solve the system\n",
    "    x = np.linalg.lstsq(A, b)[0]\n",
    "    g = x[:n]\n",
    "    lnE = x[n:n + locations]\n",
    "    lnt = x[n + locations:]\n",
    "\n",
    "    return (g, lnE, lnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silimilarly, for $N$ sample pixels in each image and $P$ images, we need $N \\times P > (Z_{max} -Z_{min}) + N + P$\n",
    "Suppose we have 3 images, $2N > 255 + 2$, $N > 129 $ should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmd = 100\n",
    "\n",
    "targetsize = 1000\n",
    "eta = 100\n",
    "sampledRP = windowSample(RP,targetsize)\n",
    "sampledGP = windowSample(GP,targetsize)\n",
    "sampledBP = windowSample(BP,targetsize)\n",
    "R_g, R_linE, R_lnt = gsolve2(sampledRP, lmd, eta = eta)\n",
    "G_g, G_linE, G_lnt = gsolve2(sampledRP, lmd, eta = eta)\n",
    "B_g, B_linE, B_lnt = gsolve2(sampledRP, lmd, eta = eta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(R_g, np.arange(256), color = \"r\")\n",
    "plt.plot(G_g, np.arange(256), color = \"g\")\n",
    "plt.plot(B_g, np.arange(256), color = \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave_prefix = 'images/cave/agia-sofia_'\n",
    "\n",
    "cave_images = np.array([image.imread(cave_prefix + \"-4.0.jpg\"),\n",
    "                       image.imread(cave_prefix + \"-2.7.jpg\"),\n",
    "                       image.imread(cave_prefix + \"-2.jpg\"),\n",
    "                       image.imread(cave_prefix + \"-1.4.jpg\"),\n",
    "                       image.imread(cave_prefix + \"-0.7.jpg\"),\n",
    "                       image.imread(cave_prefix + \"0.jpg\"),\n",
    "                       image.imread(cave_prefix + \"+1.jpg\"),\n",
    "                       image.imread(cave_prefix + \"+2.jpg\"),\n",
    "                       image.imread(cave_prefix + \"+3.jpg\"),\n",
    "                       image.imread(cave_prefix + \"+4.jpg\"),\n",
    "                       image.imread(cave_prefix + \"+5.jpg\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave_RP,cave_GP,cave_BP = imagepack(cave_images) \n",
    "\n",
    "lmd = 100\n",
    "eta = 10\n",
    "\n",
    "cave_sampledRP = windowSample(cave_RP, 100)\n",
    "cave_sampledGP = windowSample(cave_GP, 100)\n",
    "cave_sampledBP = windowSample(cave_BP, 100)\n",
    "cave_R_g, cave_R_linE, cave_R_lnt = gsolve2(cave_sampledRP, lmd, eta = eta)\n",
    "cave_G_g, cave_G_linE, cave_G_lnt = gsolve2(cave_sampledRP, lmd, eta = eta)\n",
    "cave_B_g, cave_B_linE, cave_B_lnt = gsolve2(cave_sampledRP, lmd, eta = eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(cave_images.shape[0]):\n",
    "    plt.plot(cave_R_linE + cave_R_lnt[i], cave_sampledRP[:,i], 'x')\n",
    "    \n",
    "plt.plot(cave_R_g, np.arange(256), color = 'black')\n",
    "plt.title('Pixel value over log exposure (Red)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave_lnt = np.sum([cave_R_lnt, cave_G_lnt, cave_B_lnt], axis = 0) / 3.0\n",
    "print(cave_lnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "cave_R_weight = weightgenerate(cave_R_g)\n",
    "cave_G_weight = weightgenerate(cave_G_g)\n",
    "cave_B_weight = weightgenerate(cave_B_g)\n",
    "cave_RglogE = logEEstimate(cave_R_g,cave_R_weight,cave_lnt,cave_RP)\n",
    "cave_GglogE = logEEstimate(cave_G_g,cave_G_weight,cave_lnt,cave_GP)\n",
    "cave_BglogE = logEEstimate(cave_B_g,cave_B_weight,cave_lnt,cave_BP)\n",
    "\n",
    "cave_result_img = np.zeros(cave_images[0].shape)\n",
    "cave_logEs = [cave_RglogE, cave_GglogE, cave_BglogE]\n",
    "for i in range(3):\n",
    "    cave_result_img[:,:,i] = (cave_logEs[i].reshape(cave_result_img.shape[0], cave_result_img.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave_img_linearMap = normal2image(cave_result_img).astype(np.uint8)\n",
    "cave_img_normal = image2normal(cave_result_img)\n",
    "cave_img_gamColor = normal2image(gamma(cave_img_normal, 0.3)).astype(np.uint8)\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.imshow(cave_img_gamColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "(2-4 paragraphs) summarizing your observations, results, etc.\n",
    "\n",
    "1. Take a series of bracketed images with camera on a tripod (AEB mode)\n",
    "2. Global alignment\n",
    "3. Estimate radiometric response function\n",
    "4. Estimate HDR radiance imgae by selecting / blending pixels from different exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
